{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/moej56153/Master_Thesis/old_files/IntegralClusteringTest.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/old_files/IntegralClusteringTest.ipynb#ch0000000vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mIntegralQuery\u001b[39;00m \u001b[39mimport\u001b[39;00m SearchQuery, IntegralQuery, Filter, Range \u001b[39m#################################################\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/old_files/IntegralClusteringTest.ipynb#ch0000000vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/old_files/IntegralClusteringTest.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataclasses\u001b[39;00m \u001b[39mimport\u001b[39;00m dataclass\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from IntegralQuery import SearchQuery, IntegralQuery, Filter, Range #################################################\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, SkyOffsetFrame\n",
    "from datetime import datetime\n",
    "from numba import njit\n",
    "from time import time\n",
    "\n",
    "\n",
    "@njit\n",
    "def calculate_distance_matrix(quick_list, \n",
    "                              angle_weight, \n",
    "                              time_weight, \n",
    "                              max_distance, \n",
    "                              min_ang_distance):\n",
    "    l = len(quick_list)\n",
    "    distances = np.full((l,l), 2*max_distance)\n",
    "    \n",
    "    partitions = [0]\n",
    "    for i in range(1,l):\n",
    "        if quick_list[i,2]-quick_list[i-1,2] > max_distance/time_weight:\n",
    "            partitions.append(i)\n",
    "    partitions.append(l)\n",
    "    \n",
    "    for i in range(len(partitions)-1):\n",
    "        for j in range(partitions[i], partitions[i+1]):\n",
    "\n",
    "            for k in range(j+1, partitions[i+1]):\n",
    "                distances[j,k] = distances[k,j] = calculate_distance(\n",
    "                    quick_list[j],\n",
    "                    quick_list[k],\n",
    "                    angle_weight,\n",
    "                    time_weight,\n",
    "                    min_ang_distance, \n",
    "                    max_distance)\n",
    "                \n",
    "    np.fill_diagonal(distances,0.)\n",
    "            \n",
    "    return np.array(partitions), distances\n",
    "\n",
    "@njit\n",
    "def calculate_distance(point1, point2, angle_weight, time_weight, min_ang_distance, max_distance):\n",
    "    ang_dis = np.arccos( np.clip(np.array([np.sin(point1[1])*np.sin(point2[1]) \n",
    "                                           + np.cos(point1[1])*np.cos(point2[1]) \n",
    "                                           * np.cos(point1[0] - point2[0])]),\n",
    "                                 -1., 1.) )[0]\n",
    "    \n",
    "    if ang_dis < min_ang_distance:\n",
    "        return 2.*max_distance\n",
    "    \n",
    "    time_dis = abs(point1[2] - point2[2])\n",
    "    \n",
    "    return ( (angle_weight*ang_dis)**2 + (time_weight*time_dis)**2 )**0.5\n",
    "\n",
    "@njit\n",
    "def find_regions(distances, max_distance, partitions):\n",
    "    regions = []\n",
    "    \n",
    "    for i,partition in enumerate(partitions[:-1]):\n",
    "        unconnected = [j for j in range(partition, partitions[i+1])]\n",
    "        \n",
    "        while not len(unconnected)==0:\n",
    "            temp_region = [unconnected.pop(0)]\n",
    "            search_index = 0\n",
    "            \n",
    "            while search_index < len(temp_region):\n",
    "                l = len(unconnected)\n",
    "                for j in range(l-1,-1,-1):\n",
    "                    if distances[ temp_region[search_index], unconnected[j] ] < max_distance:\n",
    "                        temp_region.append(unconnected.pop(j))\n",
    "                        \n",
    "                search_index += 1\n",
    "                \n",
    "            regions.append(sorted(temp_region))\n",
    "            \n",
    "    return regions\n",
    "\n",
    "@njit\n",
    "def choose_random_weighted_interval(weights):\n",
    "    r = np.random.random(1)[0] * np.sum(weights)\n",
    "    s = 0.\n",
    "    for i, w in enumerate(weights):\n",
    "        s += w\n",
    "        if r < s:\n",
    "            return i\n",
    "    return None\n",
    "        \n",
    "@njit\n",
    "def calc_pair_combinations(number):\n",
    "    return (number)*(number-1)/2\n",
    "    \n",
    "    \n",
    "class Cluster:\n",
    "    def __init__(self,\n",
    "                 pointing: \"Pointing\",\n",
    "                 query: \"ClusteredQuery\"):\n",
    "        \"\"\"\n",
    "        Object that represents one cluster, and stores the Pointings within that cluster, as well as\n",
    "        the average distance between pointings and the ClusteredQuery objected it was created within\n",
    "        \"\"\"\n",
    "        \n",
    "        self.indices = [pointing.index]\n",
    "        self.avg_distance = 0.\n",
    "        self.num_pointings = 1\n",
    "        self.pointings = [pointing]\n",
    "        self.query = query\n",
    "        \n",
    "    def add_pointing(self, pointing:\"Pointing\"):\n",
    "        \"\"\"Adds a new pointing to a cluster\"\"\"\n",
    "        \n",
    "        self.avg_distance = self.calc_new_avg_dist(pointing)\n",
    "        self.indices.append(pointing.index)\n",
    "        self.pointings.append(pointing)\n",
    "        self.num_pointings += 1\n",
    "        \n",
    "    def should_add_pointing(self, pointing: \"Pointing\") -> bool:\n",
    "        \"\"\"Checks if a Pointing should be added to the Cluster\"\"\"\n",
    "        if self.num_pointings < self.query._cluster_size_range[1]:\n",
    "            if self.find_new_max_dist(pointing) < self.query._max_distance:\n",
    "                if self.num_pointings >= self.query._cluster_size_range[0]:\n",
    "                    if (self.calc_new_avg_dist(pointing)/self.avg_distance\n",
    "                        < self.query._cluster_size_preference_threshold[self.num_pointings\n",
    "                                                                        - self.query._cluster_size_range[0]]):\n",
    "                        return True\n",
    "                else:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def finalize_cluster(self):\n",
    "        \"\"\"Set the cluster attribute of the Pointings in the Cluster to the Cluster\"\"\"\n",
    "        for p in self.pointings:\n",
    "            p.cluster = self\n",
    "            \n",
    "    def calc_new_avg_dist(self, pointing: \"Pointing\") -> float:\n",
    "        \"\"\"Returns the new average distance between Pointings if a Pointing were added\"\"\"\n",
    "        return ((self.avg_distance * calc_pair_combinations(self.num_pointings)\n",
    "                 + np.sum(self.query._distances[pointing.index,self.indices]))\n",
    "                 / calc_pair_combinations(self.num_pointings+1) )\n",
    "        \n",
    "    def find_new_max_dist(self, pointing: \"Pointing\") -> float:\n",
    "        \"\"\"Returns the maximum distance of a pointing with a cluster\"\"\"\n",
    "        return np.amax(self.query._distances[pointing.index,self.indices])\n",
    "\n",
    "    def find_closest_pointings(self, cluster2: \"Cluster\") -> tuple[\"Pointing\"]:\n",
    "        \"\"\"Returns the Pointing pair with the smallest distance between two clusters\"\"\"\n",
    "        d = self.query._distances[self.indices,:][:,cluster2.indices]\n",
    "        c = np.unravel_index(d.argmin(), d.shape)\n",
    "        return self.pointings[c[0]], cluster2.pointings[c[1]]\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Pointing:\n",
    "    \"\"\"\n",
    "    Dataclass that represents a single Pointing. Contains its coordinates, scw_id, index,\n",
    "    and its cluster may be added later\n",
    "    \"\"\"\n",
    "    scw_id: str\n",
    "    sky_coords: SkyCoord\n",
    "    start_time: datetime\n",
    "    index: int\n",
    "    cluster: Cluster = None\n",
    "        \n",
    "    def angle_between_three_pointings(self, \n",
    "                                      pointing2: \"Pointing\", \n",
    "                                      pointing3: \"Pointing\", \n",
    "                                      angle_weight: float, \n",
    "                                      time_weight: float\n",
    "                                      ) -> float:\n",
    "        \"\"\"Returns the angle between three different poitings. Can be thought of as\n",
    "        how much pointing2 is on the way between p and pointing3\n",
    "        \"\"\"\n",
    "        \n",
    "        origin = SkyCoord(self.sky_coords.ra.deg, (self.sky_coords.dec.deg%180.)-90., frame=\"icrs\",unit=\"deg\")\n",
    "        origin_Frame = SkyOffsetFrame(origin = origin)\n",
    "        \n",
    "        p1 = self.sky_coords.transform_to(origin_Frame)\n",
    "        p2 = pointing2.sky_coords.transform_to(origin_Frame)\n",
    "        p3 = pointing3.sky_coords.transform_to(origin_Frame)\n",
    "        \n",
    "        a_a = p2.lon.deg - p3.lon.deg\n",
    "        a_d2 = abs(p1.lat.deg - p2.lat.deg) * angle_weight\n",
    "        a_d3 = abs(p1.lat.deg - p3.lat.deg) * angle_weight\n",
    "        \n",
    "        t_d2 = (pointing2.start_time - self.start_time).total_seconds()/86400 * time_weight\n",
    "        t_d3 = (pointing3.start_time - self.start_time).total_seconds()/86400 * time_weight\n",
    "        \n",
    "        return np.arccos( np.clip((a_d2*a_d3*np.cos(np.deg2rad(a_a)) + t_d2*t_d3) \n",
    "                                  / np.linalg.norm([a_d2,t_d2]) / np.linalg.norm([a_d3,t_d3]), \n",
    "                                  -1., 1.) )\n",
    "        \n",
    "\n",
    "class ClusteredQuery:\n",
    "    def __init__(self,\n",
    "                 scw_ids: np.array, # has to be sorted by START_DATE\n",
    "                 angle_weight: float,\n",
    "                 time_weight: float,\n",
    "                 max_distance: float,\n",
    "                 min_ang_distance: float,\n",
    "                 cluster_size_range: tuple[int] = (5,5),\n",
    "                 cluster_size_preference_threshold: tuple[float] = (),\n",
    "                 failed_improvements_max: int = 3,\n",
    "                 suboptimal_cluster_size: int = 2, # >= 1\n",
    "                 close_suboptimal_cluster_size: int = 3, # >= suboptimal_cluster_size\n",
    "                 track_performance: bool = False\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        ClusteredQuery object. The main class that converts a list of scw_ids into Clusters\n",
    "        composed of Pointings.\n",
    "        \n",
    "        :param scw_ids: numpy array with SCW_ID in first column, RA (deg) in second, DEC (deg) in third,\n",
    "        and START_DATE (datetime) in the fourth column. Has to be sorted by start_date\n",
    "        \n",
    "        :param angle_weight: determines how much effective distance a seperation of 1 degree is\n",
    "        \n",
    "        :param time_weight: determines how much effective distance a seperation of 1 day is\n",
    "        \n",
    "        :param max_distance: the maximum effective distance two pointings in a cluster may have\n",
    "        \n",
    "        :param min_ang_distance: the minimum angular separation (deg) two pointing in a cluster may have\n",
    "        \n",
    "        :param cluster_size_range: the smallest and largest cluster sizes the algorithm aims to create\n",
    "        \n",
    "        :param cluster_size_preference_threshold: the thresholds for average distance ratios that are considered\n",
    "        when adding a Pointing to Cluster within the cluster_size_range\n",
    "        Example: if cluster_size_range = (3,5), then cluster_size_preference_threshold = (4.,5.) would mean that\n",
    "        a fourth pointing is only added to a cluster of 3 if the average distance does not increase four-fold,\n",
    "        and a fith would only be added if the average distance does not increase five-fold\n",
    "        Has to contain one element for each cluster size within the cluster_size_range\n",
    "        \n",
    "        :param failed_improvements_max: how many successive failed improvements are allowed before a \n",
    "        Region is declared finished\n",
    "        Use this paramter to determine the trade-off between run time and quality of clusters\n",
    "        \n",
    "        :param suboptimal_cluster_size: the maximum cluster size that is used to begin an improvement\n",
    "        Cannot be smaller than 1\n",
    "        \n",
    "        :param close_suboptimal_cluster_size: the maximum cluster size that is paired with a suboptimal cluster\n",
    "        to attempt an improvement.\n",
    "        Cannot be smaller than suboptimal_cluster_size\n",
    "        \n",
    "        :param track_performance: Should the algorithm print various performance statistics after running?\n",
    "        \"\"\"\n",
    "        \n",
    "        assert len(cluster_size_preference_threshold) == (cluster_size_range[1] - cluster_size_range[0]), \\\n",
    "                \"cluster_size_preference_threshold must cointain 1 element for each cluster_size_range\"\n",
    "        \n",
    "        assert suboptimal_cluster_size >= 1, \"suboptimal_cluster_size must be at least 1\"\n",
    "        \n",
    "        assert close_suboptimal_cluster_size >= suboptimal_cluster_size, \\\n",
    "                \"close_suboptimal_cluster_size must be at least suboptimal_cluster_size\"\n",
    "        \n",
    "        \n",
    "        self._angle_weight = float(angle_weight)\n",
    "        self._time_weight = float(time_weight)\n",
    "        self._max_distance = float(max_distance)\n",
    "        self._min_ang_distance = float(min_ang_distance)\n",
    "        self._cluster_size_range = cluster_size_range\n",
    "        self._cluster_size_preference_threshold = cluster_size_preference_threshold\n",
    "        self._failed_improvements_max = failed_improvements_max\n",
    "        self._suboptimal_cluster_size_range = (1, suboptimal_cluster_size)\n",
    "        self._close_suboptimal_cluster_size_range = (1, close_suboptimal_cluster_size)\n",
    "        \n",
    "        self._num_pointings = len(scw_ids)\n",
    "        \n",
    "        self._track_performance = track_performance\n",
    "        if self._track_performance:\n",
    "            start_time = time()\n",
    "            self._region_sizes = {}\n",
    "            self._initial_cluster_sizes = self.initialize_size_dictionary()\n",
    "            self._cluster_sizes = self.initialize_size_dictionary()\n",
    "            for i in self._initial_cluster_sizes.keys():\n",
    "                self._initial_cluster_sizes[i] = 0\n",
    "                self._cluster_sizes[i] = 0\n",
    "            self._attempted_improvements = 0\n",
    "            self._implemented_improvements = 0\n",
    "            self._dead_ends = 0\n",
    "        \n",
    "        \n",
    "        quick_list = np.zeros((self._num_pointings, 3))\n",
    "        quick_list[:,0:2] = scw_ids[:,1:3]\n",
    "        quick_list[:,0:2] = np.deg2rad(quick_list[:,0:2])\n",
    "        for i in range(self._num_pointings):\n",
    "            quick_list[i,2] = (scw_ids[i,3] - datetime(2000,1,1,0,0,0)).total_seconds()/86400  \n",
    "            \n",
    "        partitions, self._distances = calculate_distance_matrix(\n",
    "            quick_list, np.rad2deg(angle_weight), time_weight,\n",
    "            self._max_distance, np.deg2rad(self._min_ang_distance)\n",
    "            )\n",
    "                \n",
    "        self._region_indices = find_regions(self._distances, self._max_distance, partitions)\n",
    "        \n",
    "        self._pointings = np.array(\n",
    "            [Pointing(pointing[0], \n",
    "                      SkyCoord(pointing[1],pointing[2],frame=\"icrs\",unit=\"deg\"),\n",
    "                      pointing[3], \n",
    "                      index)\n",
    "             for index, pointing in enumerate(scw_ids)]\n",
    "            )\n",
    "        \n",
    "        self.clusters = self.initialize_size_dictionary()\n",
    "        \n",
    "        for i in self._region_indices:\n",
    "            Region(i, self)\n",
    "            \n",
    "        if self._track_performance:\n",
    "            for i in self._region_indices:\n",
    "                if len(i) in self._region_sizes:\n",
    "                    self._region_sizes[len(i)] += 1\n",
    "                else:\n",
    "                    self._region_sizes[len(i)] = 1\n",
    "            for clusters in self.clusters.values():\n",
    "                for cluster in clusters:\n",
    "                    self._cluster_sizes[cluster.num_pointings] += 1\n",
    "            \n",
    "        # print()\n",
    "        # print(\"All Done\")\n",
    "        # clustered = set()\n",
    "        # n = 0\n",
    "        \n",
    "        # for key, value in self.clusters.items():\n",
    "        #     for c in value:\n",
    "        #         print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        #         clustered = clustered | set(c.indices)\n",
    "        #         n += c.num_pointings\n",
    "                \n",
    "        # missing = [i for i in range(self._num_pointings) if i not in clustered]\n",
    "        # print()\n",
    "        # print(missing)\n",
    "        # print(self._num_pointings, n)\n",
    "        # print()\n",
    "        \n",
    "        if self._track_performance:\n",
    "            end_time = time()\n",
    "            print(\"Performance Review!\")\n",
    "            print()\n",
    "            print(\"Run Time:\")\n",
    "            print(f\"{(end_time - start_time):.2f}s\")\n",
    "            print()\n",
    "            print(\"Region Sizes:\")\n",
    "            print(sorted(self._region_sizes.items()))\n",
    "            print()\n",
    "            print(\"Initial Cluster Sizes:\")\n",
    "            print(self._initial_cluster_sizes)\n",
    "            print()\n",
    "            print(\"Final Cluster Sizes:\")\n",
    "            print(self._cluster_sizes)\n",
    "            print()\n",
    "            print(\"Attempted Improvements:\")\n",
    "            print(self._attempted_improvements)\n",
    "            print()\n",
    "            print(\"Implemented Improvements:\")\n",
    "            print(self._implemented_improvements)\n",
    "            print()\n",
    "            print(\"Dead-End Clustering Paths:\")\n",
    "            print(self._dead_ends)\n",
    "            \n",
    "                    \n",
    "    def initialize_size_dictionary(self) -> dict[list]:\n",
    "        \"\"\"Returns dictionary with empty list for each cluster size\"\"\"\n",
    "        dict = {}\n",
    "        for i in range(self._cluster_size_range[1]):\n",
    "            dict[i+1]=[]\n",
    "        return dict\n",
    "    \n",
    "    def get_clustered_scw_ids(self) -> dict[list[str]]:\n",
    "        \"\"\"Returns dictionary with lists of SCW_IDs in clusters, arranged by cluster size\"\"\"\n",
    "        scw_id_clusters = self.initialize_size_dictionary()\n",
    "        for size, clusters in self.clusters.items():\n",
    "            for cluster in clusters:\n",
    "                scw_id_clusters[size].append([p.scw_id for p in cluster.pointings])\n",
    "        return scw_id_clusters\n",
    "\n",
    "    \n",
    "class Region:\n",
    "    def __init__(self,\n",
    "                 region_indices: list,\n",
    "                 query: ClusteredQuery\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Object created by ClusteredQuery that clusters pointings together\n",
    "        :param region_indices: list of indices that are to be clustered by this Region\n",
    "        :param query: the ClusteredQuery object that created this Region\n",
    "        \"\"\"\n",
    "        \n",
    "        self.indices = region_indices\n",
    "        self.query = query\n",
    "        \n",
    "        self.clusters = self.query.initialize_size_dictionary()\n",
    "        self.potential_clusters1 = self.query.initialize_size_dictionary()\n",
    "        self.potential_clusters2 = self.query.initialize_size_dictionary()\n",
    "            \n",
    "        # print()\n",
    "        # print(\"Initial Clustering!\")\n",
    "        # print()\n",
    "        self.initial_clustering()\n",
    "        \n",
    "        if self.query._track_performance:\n",
    "            for clusters in self.clusters.values():\n",
    "                for cluster in clusters:\n",
    "                    self.query._initial_cluster_sizes[cluster.num_pointings] += 1\n",
    "        \n",
    "        # for key, value in self.clusters.items():\n",
    "        #     for c in value:\n",
    "        #         print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        \n",
    "        \n",
    "        failed_improvements = 0\n",
    "        while failed_improvements < self.query._failed_improvements_max and self.has_suboptimal_clusters():\n",
    "            if self.query._track_performance:\n",
    "                self.query._attempted_improvements += 1\n",
    "                \n",
    "            if not self.attempt_improvement():\n",
    "                failed_improvements += 1\n",
    "                \n",
    "            else:\n",
    "                failed_improvements = 0\n",
    "                if self.query._track_performance:\n",
    "                    self.query._implemented_improvements += 1\n",
    "                \n",
    "        for size, clusters in self.clusters.items():\n",
    "            self.query.clusters[size].extend(clusters)\n",
    "        \n",
    "        # print()\n",
    "        # print()\n",
    "        # print(\"Finishing Region!\")\n",
    "        # print()\n",
    "        # print()\n",
    "                \n",
    "    \n",
    "    def initial_clustering(self):\n",
    "        \"\"\"Function that clusters previously unclustered pointings\"\"\"\n",
    "        for position, index in enumerate(self.indices):\n",
    "            if self.query._pointings[index].cluster is None:\n",
    "                # print()\n",
    "                # print(f\"New Cluster: {position}, {index}\")\n",
    "                cluster = Cluster(self.query._pointings[index], self.query)\n",
    "                self.add_following_pointings(cluster, position+1)\n",
    "                cluster.finalize_cluster()\n",
    "                self.clusters[cluster.num_pointings].append(cluster)\n",
    "                \n",
    "        \n",
    "    def add_following_pointings(self, cluster: Cluster, position: int):\n",
    "        \"Called by initial_clustering, tries to add succesive Pointings to Cluster\"\n",
    "        if cluster.num_pointings < self.query._cluster_size_range[1]:\n",
    "            \n",
    "            # Performance may be optimized via this value\n",
    "            for position2, index in enumerate(\n",
    "                self.indices[position : position + 20*self.query._cluster_size_range[1]]\n",
    "                ):\n",
    "                \n",
    "                if self.query._pointings[index].cluster is None:\n",
    "                    # print(f\"Checking: {position+position2}, {index}\")\n",
    "                    if cluster.should_add_pointing(self.query._pointings[index]):\n",
    "                        # print(f\"Adding: {position+position2}, {index}\")\n",
    "                        cluster.add_pointing(self.query._pointings[index])\n",
    "                        self.add_following_pointings(cluster, position+position2+1)\n",
    "                        break\n",
    "        \n",
    "    def attempt_improvement(self) -> bool:\n",
    "        \"\"\"Function that attempts to improve a clusering\n",
    "        It does this by connecting a suboptimal_cluster to a close_suboptimal_cluster\n",
    "        via a path of connecting clusters, then reclusters all of the selected clusters,\n",
    "        and finally checks if the resulting clustering is an improvement over the existing clustering.\n",
    "        If yes, it will keep the new clustering, if no then not\n",
    "        \"\"\"\n",
    "        # print()\n",
    "        # print(\"Attempting Improvement!\")\n",
    "        # print()\n",
    "        c1 = self.find_suboptimal_cluster()\n",
    "        c2 = self.find_close_suboptimal_cluster(c1)\n",
    "        found_path, recluster_indices = self.find_cluster_path(c1,c2)\n",
    "        if not found_path:\n",
    "            return False\n",
    "        else:\n",
    "            self.recluster_pointings(recluster_indices, c1)\n",
    "        \n",
    "        # print()\n",
    "        # print(\"Done!\")\n",
    "        # print()\n",
    "        # for key, value in self.clusters.items():\n",
    "        #     for c in value:\n",
    "        #         print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        # print()\n",
    "        # for key, value in self.potential_clusters1.items():\n",
    "        #     for c in value:\n",
    "        #         print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        # print()\n",
    "        # for key, value in self.potential_clusters2.items():\n",
    "        #     for c in value:\n",
    "        #         print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        # print(f\"Comparison: {self.calc_clustering_cost(self.potential_clusters1)}, {self.calc_clustering_cost(self.potential_clusters2)}\")\n",
    "        \n",
    "        if self.calc_clustering_cost(self.potential_clusters1) > self.calc_clustering_cost(self.potential_clusters2):\n",
    "            self.implement(self.potential_clusters2, True)\n",
    "            # print()\n",
    "            # print(\"Implemented!\")\n",
    "            # for key, value in self.clusters.items():\n",
    "            #     for c in value:\n",
    "            #         print(f\"{c.indices}, {c.avg_distance}\")\n",
    "            # print()\n",
    "            return True\n",
    "        else:\n",
    "            self.implement(self.potential_clusters1, False)\n",
    "            # print()\n",
    "            # print(\"Rejected!\")\n",
    "            # for key, value in self.clusters.items():\n",
    "            #     for c in value:\n",
    "            #         print(f\"{c.indices}, {c.avg_distance}\")\n",
    "            # print()\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    def find_suboptimal_cluster(self) -> Cluster:\n",
    "        \"\"\"Chooses a cluster in the suboptimal_cluser_size_range\"\"\"\n",
    "        size_weights = np.array([len(self.clusters[i]) / i**2\n",
    "                                 for i in range(self.query._suboptimal_cluster_size_range[0],\n",
    "                                                self.query._suboptimal_cluster_size_range[1] + 1)])\n",
    "        \n",
    "        size = choose_random_weighted_interval(size_weights) + 1\n",
    "        index = np.random.randint(len(self.clusters[size]))\n",
    "        \n",
    "        cluster = self.clusters[size].pop(index)\n",
    "        self.potential_clusters1[size].append(cluster)\n",
    "        \n",
    "        return cluster\n",
    "    \n",
    "    def find_close_suboptimal_cluster(self, cluster: Cluster) -> Cluster:\n",
    "        \"\"\"Chooses a close cluster in the close_suboptimal_cluster_size_range\"\"\"\n",
    "        clusters = []\n",
    "        cluster_size_indices = [0]\n",
    "        \n",
    "        for i in range(self.query._close_suboptimal_cluster_size_range[0], \n",
    "                       self.query._close_suboptimal_cluster_size_range[1] + 1):\n",
    "            clusters.extend(self.clusters[i])\n",
    "            cluster_size_indices.append( len(self.clusters[i]) + cluster_size_indices[i-1] )\n",
    "            \n",
    "        cluster_weights = np.zeros(len(clusters))\n",
    "        \n",
    "        # Performance may be optimized via this value\n",
    "        for i, c in enumerate(clusters):\n",
    "            d = self.query._distances[cluster.indices,:][:,c.indices]\n",
    "            cluster_weights[i] = np.exp( -5.*np.amin(d) / self.query._max_distance )\n",
    "            \n",
    "        for i in range(1, self.query._close_suboptimal_cluster_size_range[1] + 1):\n",
    "            cluster_weights[cluster_size_indices[i-1]:cluster_size_indices[i]] /= i\n",
    "        \n",
    "        index = choose_random_weighted_interval( cluster_weights )\n",
    "        \n",
    "        for size, csi in enumerate(cluster_size_indices):\n",
    "            if not index >= csi:\n",
    "                break\n",
    "        \n",
    "        true_index = index - cluster_size_indices[size-1]\n",
    "        \n",
    "        cluster2 = self.clusters[size].pop(true_index)\n",
    "        self.potential_clusters1[size].append(cluster2)\n",
    "        \n",
    "        return cluster2\n",
    "        \n",
    "    def find_cluster_path(self, cluster1: Cluster, cluster2: Cluster) -> tuple[bool, set]:\n",
    "        \"\"\"Connects two clusters via a path of inbetween clusters\"\"\"\n",
    "        indices_in = set(cluster1.indices)\n",
    "        indices_to = set(cluster2.indices)\n",
    "        arrived = False\n",
    "        \n",
    "        while not arrived:\n",
    "            indices_out = np.array([i for i in self.indices if i not in indices_in])\n",
    "            pointing1, pointing2 = cluster1.find_closest_pointings(cluster2)\n",
    "            # print(pointing1.index, pointing2.index, self.query._distances[pointing1.index, pointing2.index])\n",
    "\n",
    "            # Performance may be optimized via this value\n",
    "            close_indices = self.find_closest_points(pointing1.index, indices_out, 5)\n",
    "            # print(close_indices)\n",
    "            \n",
    "            angle = np.vectorize(lambda p: pointing1.angle_between_three_pointings(\n",
    "                pointing2, p, self.query._angle_weight,self.query._time_weight\n",
    "                ))\n",
    "            \n",
    "            angles_filtered = angle(self.query._pointings[close_indices])\n",
    "            \n",
    "            distances_filtered = self.query._distances[pointing1.index, close_indices]\n",
    "            \n",
    "            # Performance may be optimized via this value\n",
    "            close_indices_weights = ((distances_filtered < self.query._max_distance) \n",
    "                                     * np.exp(-4. * distances_filtered / self.query._max_distance) \n",
    "                                     * np.cos(angles_filtered/2.)**8)\n",
    "            \n",
    "            # print(angles_filtered)\n",
    "            # print(distances_filtered)\n",
    "            # print(close_indices_weights)\n",
    "            \n",
    "            random_index = choose_random_weighted_interval(close_indices_weights)\n",
    "            \n",
    "            if (random_index is None) or (np.amax(np.cos(angles_filtered)) < 0.):\n",
    "                # print(\"Cannot go forwards, or reached dead end!\")\n",
    "                self.implement(self.potential_clusters1, False)\n",
    "                if self.query._track_performance:\n",
    "                    self.query._dead_ends += 1\n",
    "                return False, None\n",
    "\n",
    "            index = close_indices[random_index]\n",
    "            \n",
    "            cluster1 = self.query._pointings[index].cluster\n",
    "            indices_in = indices_in | set(cluster1.indices)\n",
    "            if index in indices_to:\n",
    "                arrived = True\n",
    "            else:\n",
    "                self.clusters[cluster1.num_pointings].remove(cluster1)\n",
    "                self.potential_clusters1[cluster1.num_pointings].append(cluster1)\n",
    "        \n",
    "        return True, indices_in\n",
    "        \n",
    "        \n",
    "    def recluster_pointings(self, recluster_indices: list[int], start_cluster: Cluster):\n",
    "        \"\"\"Takes existing clusters and reclusters them into new clusters\"\"\"\n",
    "        # Performance may be optimized via this value\n",
    "        index = start_cluster.indices[\n",
    "            choose_random_weighted_interval(np.exp(\n",
    "                np.average(self.query._distances[start_cluster.indices,:][:,list(recluster_indices)], axis=1) \n",
    "                * 4. / self.query._max_distance))\n",
    "            ]\n",
    "        \n",
    "        cluster = Cluster(self.query._pointings[index], self.query)\n",
    "        already_clustered = {index}\n",
    "        not_clustered = np.array([i for i in recluster_indices if i not in already_clustered])\n",
    "        \n",
    "        # print()\n",
    "        # print(\"Recluster Pointings!\")\n",
    "        \n",
    "        added_all_clusters = False\n",
    "        while not_clustered.size != 0:\n",
    "            # print()\n",
    "            # print(\"New Cluster!\")\n",
    "\n",
    "            cluster_done = False\n",
    "            \n",
    "            while not cluster_done:\n",
    "                # print()\n",
    "                # print(\"Continue Cluster!\")\n",
    "                # print(index, cluster.indices)\n",
    "                # print(already_clustered)\n",
    "                # print(not_clustered)\n",
    "                \n",
    "                # Performance may be optimized via this value\n",
    "                close_indices = self.find_closest_points(index, not_clustered, 5)\n",
    "                \n",
    "                internal_distances = np.average(self.query._distances[cluster.indices,:][:,close_indices], axis=0)\n",
    "                external_distances = np.average(self.query._distances[close_indices,:][:,close_indices], axis=0)\n",
    "                \n",
    "                # Performance may be optimized via this value\n",
    "                close_indices_weights = np.exp( (5.*external_distances - 4.*internal_distances) \n",
    "                                                / self.query._max_distance )\n",
    "                \n",
    "                # print(close_indices)\n",
    "                # print(internal_distances)\n",
    "                # print(external_distances)\n",
    "                # print(close_indices_weights)\n",
    "                \n",
    "                added = False\n",
    "                while not added:\n",
    "                    random_index = choose_random_weighted_interval(close_indices_weights)\n",
    "                    # print(random_index)\n",
    "                    if random_index is None:\n",
    "                        cluster_done = True\n",
    "                        # print(\"Found None!\")\n",
    "                        break\n",
    "                    \n",
    "                    index = close_indices[random_index]\n",
    "                    # print(index)\n",
    "                    if cluster.should_add_pointing(self.query._pointings[index]):\n",
    "                        added = True\n",
    "                        cluster.add_pointing(self.query._pointings[index])\n",
    "                        already_clustered.add(index)\n",
    "                        not_clustered = np.array([i for i in recluster_indices if i not in already_clustered])\n",
    "                        \n",
    "                        # print(\"Added!\")\n",
    "                        \n",
    "                        if cluster.num_pointings == self.query._cluster_size_range[1]:\n",
    "                            cluster_done = True\n",
    "                        \n",
    "                    else:\n",
    "                        close_indices_weights[random_index] = 0.\n",
    "                \n",
    "                if not_clustered.size == 0:\n",
    "                    self.potential_clusters2[cluster.num_pointings].append(cluster)\n",
    "                    added_all_clusters = True\n",
    "                    break\n",
    "                \n",
    "                if cluster_done:\n",
    "                    self.potential_clusters2[cluster.num_pointings].append(cluster)\n",
    "                    \n",
    "                    # Performance may be optimized via this value\n",
    "                    weights = np.exp(4.*external_distances / self.query._max_distance)\n",
    "                     \n",
    "                    if added:\n",
    "                        weights[random_index] = 0.\n",
    "                    index = close_indices[choose_random_weighted_interval(weights)]\n",
    "                    \n",
    "                    cluster = Cluster(self.query._pointings[index], self.query)\n",
    "                    already_clustered.add(index)\n",
    "                    not_clustered = np.array([i for i in recluster_indices if i not in already_clustered])\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    index = cluster.indices[np.random.randint(cluster.num_pointings)]\n",
    "                    \n",
    "        if not added_all_clusters:\n",
    "            self.potential_clusters2[cluster.num_pointings].append(cluster)\n",
    "            \n",
    "    def find_closest_points(self, start_index: int, search_indices: list[int], number_multiplier: int) -> list[int]:\n",
    "        \"\"\"Returns a list of the pointings closest to a pointing froma list of pointings\"\"\"\n",
    "        num_points = min(len(search_indices), self.query._cluster_size_range[1]*number_multiplier)\n",
    "        sortable_pointings = [i for i in range(num_points)]\n",
    "        distances = self.query._distances[start_index,search_indices]\n",
    "        return search_indices[np.argpartition(distances, sortable_pointings)[:num_points]]\n",
    "            \n",
    "    def calc_clustering_cost(self, cluster_dict: dict[list[Cluster]]) -> float:\n",
    "        \"\"\"Return a cost for a clustering configuration. Lower is better\"\"\"\n",
    "        n = 0\n",
    "        avg_d = 0.\n",
    "        for clusters in cluster_dict.values():\n",
    "            for cluster in clusters:\n",
    "                n += 1\n",
    "                if cluster.num_pointings == 1:\n",
    "                    avg_d += self.query._max_distance\n",
    "                else:\n",
    "                    avg_d += cluster.avg_distance\n",
    "\n",
    "        return n + avg_d/n / self.query._max_distance\n",
    "    \n",
    "    def has_suboptimal_clusters(self) -> bool:\n",
    "        \"\"\"Checks if enough suboptimal clusters exist to attempt an improvment\"\"\"\n",
    "        s = 0\n",
    "        for i in range(self.query._suboptimal_cluster_size_range[0], \n",
    "                       self.query._suboptimal_cluster_size_range[1] + 1):\n",
    "            s += len(self.clusters[i])\n",
    "        if s >= 2:\n",
    "            return True\n",
    "        elif s >= 1:\n",
    "            for i in range(self.query._suboptimal_cluster_size_range[1] + 1,\n",
    "                           self.query._close_suboptimal_cluster_size_range[1] + 1):\n",
    "                s += len(self.clusters[i])\n",
    "            if s >= 2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def implement(self, potential_clusters: dict[list[Cluster]], finalize: bool):\n",
    "        \"\"\"Implements a clustering configuration by adding it to the main cluster dictionary\"\"\"\n",
    "        for size, clusters in potential_clusters.items():\n",
    "            if finalize:\n",
    "                for cluster in clusters:\n",
    "                    cluster.finalize_cluster()\n",
    "            self.clusters[size].extend(clusters)\n",
    "        self.potential_clusters1 = self.query.initialize_size_dictionary()\n",
    "        self.potential_clusters2 = self.query.initialize_size_dictionary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'ISO' did not parse as fits unit: At col 0, Unit 'ISO' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    }
   ],
   "source": [
    "# searchquerry = SearchQuery(object_name=\"Cyg X-1\")\n",
    "\n",
    "p = SkyCoord(83.6333, 22.0144, frame=\"icrs\", unit=\"deg\")\n",
    "searchquerry = SearchQuery(position=p, radius=\"10 degree\")\n",
    "\n",
    "cat = IntegralQuery(searchquerry)\n",
    "f = Filter(SCW_TYPE=\"POINTING\")\n",
    "scw_ids = cat.apply_filter(f,True)\n",
    "print(len(scw_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "suboptimal_cluster_size must be at least 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=0'>1</a>\u001b[0m test \u001b[39m=\u001b[39m ClusteredQuery(scw_ids, \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m6\u001b[39;49m, \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m15\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=1'>2</a>\u001b[0m                       cluster_size_range \u001b[39m=\u001b[39;49m (\u001b[39m5\u001b[39;49m,\u001b[39m5\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m                       cluster_size_preference_threshold \u001b[39m=\u001b[39;49m (),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m                       failed_improvements_max \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=4'>5</a>\u001b[0m                       suboptimal_cluster_size \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=5'>6</a>\u001b[0m                       close_suboptimal_cluster_size \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=6'>7</a>\u001b[0m                       track_performance\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb Cell 3\u001b[0m in \u001b[0;36mClusteredQuery.__init__\u001b[0;34m(self, scw_ids, angle_weight, time_weight, max_distance, min_ang_distance, cluster_size_range, cluster_size_preference_threshold, failed_improvements_max, suboptimal_cluster_size, close_suboptimal_cluster_size, track_performance)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=206'>207</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=207'>208</a>\u001b[0m \u001b[39mClusteredQuery object. The main class that converts a list of scw_ids into Clusters\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=208'>209</a>\u001b[0m \u001b[39mcomposed of Pointings.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=241'>242</a>\u001b[0m \u001b[39m:param track_performance: Should the algorithm print various performance statistics after running?\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=242'>243</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=244'>245</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(cluster_size_preference_threshold) \u001b[39m==\u001b[39m (cluster_size_range[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m cluster_size_range[\u001b[39m0\u001b[39m]), \\\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=245'>246</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcluster_size_preference_threshold must cointain 1 element for each cluster_size_range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=247'>248</a>\u001b[0m \u001b[39massert\u001b[39;00m suboptimal_cluster_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msuboptimal_cluster_size must be at least 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=249'>250</a>\u001b[0m \u001b[39massert\u001b[39;00m close_suboptimal_cluster_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m suboptimal_cluster_size, \\\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=250'>251</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclose_suboptimal_cluster_size must be at least suboptimal_cluster_size\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/moej56153/Master_Thesis/IntegralClusteringTest.ipynb#ch0000002vscode-remote?line=253'>254</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_angle_weight \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(angle_weight)\n",
      "\u001b[0;31mAssertionError\u001b[0m: suboptimal_cluster_size must be at least 1"
     ]
    }
   ],
   "source": [
    "test = ClusteredQuery(scw_ids, 1/6, 1/15, 1, 0.3, \n",
    "                      cluster_size_range = (5,5),\n",
    "                      cluster_size_preference_threshold = (),\n",
    "                      failed_improvements_max = 2,\n",
    "                      suboptimal_cluster_size = 2,\n",
    "                      close_suboptimal_cluster_size = 3,\n",
    "                      track_performance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['005500820010', '005500830010', '005800240010'],\n",
       " ['004400960020', '004500020010', '004500850010'],\n",
       " ['010200360010', '010200240010', '010200260010'],\n",
       " ['012600290010', '012600420010', '012700020020'],\n",
       " ['017000920010', '017000930010', '017000940010'],\n",
       " ['017000770010', '017000690010', '017000510010'],\n",
       " ['030000920010', '030000940010', '030000930010'],\n",
       " ['036500800020', '036501020010', '036501040010'],\n",
       " ['036500800030', '036501030010', '036501040020'],\n",
       " ['036500810010', '036501060010', '036501070010'],\n",
       " ['042200260010', '042200420010', '042200960010'],\n",
       " ['072700130010', '072700390010', '072700530010'],\n",
       " ['077400520010', '077400650010', '077400670010'],\n",
       " ['077400530010', '077400570010', '077400680010'],\n",
       " ['077400540010', '077400590010', '077400640010'],\n",
       " ['077400550010', '077400600010', '077400610010'],\n",
       " ['077400890010', '077401000010', '077401050010'],\n",
       " ['077400900010', '077401010010', '077401060010'],\n",
       " ['077400920010', '077400950010', '077400980010'],\n",
       " ['077400740010', '077400780010', '077400850010'],\n",
       " ['083901120010', '083901130010', '083901140010'],\n",
       " ['091700150010', '091700160010', '091700170010'],\n",
       " ['097000130010', '097000020010', '096700710010'],\n",
       " ['101901110010', '101900780010', '101901090010'],\n",
       " ['108900030010', '108900020010', '108900400010'],\n",
       " ['108900530010', '108900410010', '108900420010'],\n",
       " ['122100780010', '122100870010', '122100860010'],\n",
       " ['126900940010', '126901000010', '126901010010'],\n",
       " ['134200170010', '134200180010', '134200200010'],\n",
       " ['146200810010', '146600880010', '146600890010'],\n",
       " ['145600230010', '145600330010', '145600340010'],\n",
       " ['144700860010', '144700830010', '144700840010'],\n",
       " ['150500530010', '150800050010', '150800080010'],\n",
       " ['152800240010', '152800250010', '152800260010'],\n",
       " ['151500360010', '151600490010', '151600480010'],\n",
       " ['158100200010', '158100210010', '158100220010'],\n",
       " ['159900410010', '159800440010', '159800330010'],\n",
       " ['166700560010', '166400220010', '166400210010'],\n",
       " ['166400010010', '166700670010', '166700750010'],\n",
       " ['166700480010', '166700710010', '166700740010'],\n",
       " ['166200520010', '166700720010', '166700730010'],\n",
       " ['173600040010', '173600140010', '173600150010'],\n",
       " ['172400520010', '172800690010', '172800760010'],\n",
       " ['178400060010', '178400420010', '178400350010'],\n",
       " ['178500380010', '178400430010', '178500020010'],\n",
       " ['178500270010', '178500370010', '178500040010'],\n",
       " ['178500170010', '178400300010', '178500160010'],\n",
       " ['185600160010', '185600180010', '185600190010'],\n",
       " ['185600250010', '185600240010', '185600150010'],\n",
       " ['185600280010', '185700170010', '185600270010'],\n",
       " ['207800560010', '207400170010', '207400260010'],\n",
       " ['213700100010', '213700150010', '213700160010'],\n",
       " ['213700130010', '213700220010', '213700230010'],\n",
       " ['213700240010', '213700250010', '213500060010'],\n",
       " ['212600280010', '213100070010', '213100060010'],\n",
       " ['221500520020', '221500610010', '221500500010'],\n",
       " ['228400320010', '228400460010', '228100160010'],\n",
       " ['235300600010', '235300610010', '235300690010'],\n",
       " ['233100830020', '233600720010', '233600800010'],\n",
       " ['240500490010', '240900040010', '240900150010'],\n",
       " ['241300690020', '241800130010', '241800220010'],\n",
       " ['242500300010', '242500400010', '242500410010'],\n",
       " ['240900130010', '240900160010', '241300580010'],\n",
       " ['248700630010', '249000070010', '249000080010']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = test.get_clustered_scw_ids()\n",
    "r[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('MT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77c6aaad9a34bae581a83e51509dc60b9a05d4f3ba3ef918f772e036566f2e96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

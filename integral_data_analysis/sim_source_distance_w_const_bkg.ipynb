{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m The naima package is not available. Models that depend on it will not be available\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m The GSL library or the pygsl wrapper cannot be loaded. Models that depend on it will not be available.\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m The ebltable package is not available. Models that depend on it will not be available\u001b[0m\n",
      "[\u001b[32mINFO    \u001b[0m]\u001b[32m Starting 3ML!\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m no display variable set. using backend for graphics without display (agg)\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m ROOT minimizer not available\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m PyGMO is not available\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m The cthreeML package is not installed. You will not be able to use plugins which require the C/C++ interface (currently HAWC)\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m Could not import plugin HAWCLike.py. Do you have the relative instrument software installed and configured?\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m Could not import plugin FermiLATLike.py. Do you have the relative instrument software installed and configured?\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m No fermitools installed\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m Env. variable OMP_NUM_THREADS is not set. Please set it to 1 for optimal performances in 3ML\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m Env. variable MKL_NUM_THREADS is not set. Please set it to 1 for optimal performances in 3ML\u001b[0m\n",
      "[\u001b[35mWARNING \u001b[0m]\u001b[35m Env. variable NUMEXPR_NUM_THREADS is not set. Please set it to 1 for optimal performances in 3ML\u001b[0m\n",
      "Using the irfs that are valid between Start and 03/07/06 06:00:00 (YY/MM/DD HH:MM:SS)\n",
      "Using the irfs that are valid between 03/07/06 06:00:00 and 04/07/17 08:20:06 (YY/MM/DD HH:MM:SS)\n",
      "Using the irfs that are valid between 04/07/17 08:20:06 and 09/02/19 09:59:57 (YY/MM/DD HH:MM:SS)\n",
      "Using the irfs that are valid between 09/02/19 09:59:57 and 10/05/27 12:45:00 (YY/MM/DD HH:MM:SS)\n",
      "Using the irfs that are valid between 10/05/27 12:45:00 and present (YY/MM/DD HH:MM:SS)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "from astropy.table import Table\n",
    "from astromodels import Powerlaw,  PointSource, SpectralComponent\n",
    "import astropy.time as at\n",
    "from datetime import datetime\n",
    "from pyspi.utils.function_utils import find_response_version\n",
    "from pyspi.utils.response.spi_response_data import ResponseDataRMF\n",
    "from pyspi.utils.response.spi_response import ResponseRMFGenerator\n",
    "from pyspi.utils.response.spi_drm import SPIDRM\n",
    "from pyspi.utils.livedets import get_live_dets\n",
    "import os\n",
    "from MultinestClusterFit import powerlaw_binned_spectrum\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"crab_data/0374\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ra, source_dec = 10, -40\n",
    "source_piv = 100.\n",
    "source_Ks = [0.5e-4, 2e-4, 8e-4]\n",
    "source_indices = [-0.5, -2, -8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing_index = 1\n",
    "\n",
    "data_path_d = \"simulated_data/0374_const_bkg\"\n",
    "\n",
    "if not os.path.exists(f\"{data_path_d}\"):\n",
    "    os.mkdir(f\"{data_path_d}\")\n",
    "    \n",
    "with open(f\"./{data_path_d}/source_params.pickle\", \"wb\") as f:\n",
    "    pickle.dump((source_ra, source_dec, source_piv, source_Ks, source_indices), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Bins\n",
    "with fits.open(f\"{data_path}/energy_boundaries.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    energy_bins = np.append(t[\"E_MIN\"], t[\"E_MAX\"][-1])\n",
    "    \n",
    "# Pointings and Start Times\n",
    "with fits.open(f\"{data_path}/pointing.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    \n",
    "    pointings = np.array(t[\"PTID_SPI\"])\n",
    "    \n",
    "    time_start = np.array(t[\"TSTART\"]) + 2451544.5\n",
    "    time_start = [at.Time(f\"{i}\", format=\"jd\").datetime for i in time_start]\n",
    "    time_start = np.array([datetime.strftime(i,'%y%m%d %H%M%S') for i in time_start])\n",
    "    \n",
    "# Time Elapsed\n",
    "# det=i, pointing_index=j : index = j*85 + i\n",
    "with fits.open(f\"{data_path}/dead_time.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    time_elapsed = np.array(t[\"LIVETIME\"])\n",
    "    \n",
    "updated_time = t.copy()\n",
    "    \n",
    "for i in range(int(len(time_elapsed) / 85)):\n",
    "    if i == pointing_index:\n",
    "        continue\n",
    "    else:\n",
    "        updated_time[i*85 : (i+1)*85] = updated_time[pointing_index*85 : (pointing_index+1)*85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only necessary for 1380\n",
    "skip_pointing = [False] * len(pointings)\n",
    "# skip_pointing[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "\n",
    "with fits.open(f\"{data_path}/evts_det_spec_orig.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    \n",
    "background_counts = t.copy()\n",
    "\n",
    "for i in range(int(len(background_counts) / 85)):\n",
    "    if i == pointing_index:\n",
    "        continue\n",
    "    else:\n",
    "        background_counts[i*85 : (i+1)*85] = background_counts[pointing_index*85 : (pointing_index+1)*85]\n",
    "        \n",
    "background_counts[\"COUNTS\"] = np.random.poisson(background_counts[\"COUNTS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the irfs that are valid between 04/07/17 08:20:06 and 09/02/19 09:59:57 (YY/MM/DD HH:MM:SS)\n"
     ]
    }
   ],
   "source": [
    "assert find_response_version(time_start[0]) == find_response_version(time_start[-1]), \"Versions not constant\"\n",
    "version = find_response_version(time_start[0])\n",
    "rsp_base = ResponseDataRMF.from_version(version)\n",
    "\n",
    "\n",
    "resp_mats = []\n",
    "emod = np.geomspace(10, 3000, 50)\n",
    "\n",
    "for p_i, pointing in enumerate(pointings):\n",
    "    if skip_pointing[p_i]:\n",
    "        continue\n",
    "    \n",
    "    time = time_start[p_i]\n",
    "    dets = get_live_dets(time=time, event_types=[\"single\"])\n",
    "    \n",
    "    rmfs = []\n",
    "    for d in dets:\n",
    "        rmfs.append(ResponseRMFGenerator.from_time(time, d, energy_bins, emod, rsp_base))\n",
    "        \n",
    "    sds = np.empty(0)\n",
    "    for d in range(len(dets)):\n",
    "        sd = SPIDRM(rmfs[d], source_ra, source_dec)\n",
    "        sds = np.append(sds, sd.matrix.T)\n",
    "    resp_mats.append(sds.reshape((len(dets), len(emod)-1, len(energy_bins)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_count_rates(resp_mats, ra, dec, piv, K, index):\n",
    "    pl = Powerlaw()\n",
    "    pl.piv = piv\n",
    "    pl.K = K\n",
    "    pl.index = index\n",
    "    component1 = SpectralComponent(\"pl\", shape=pl)\n",
    "    source = PointSource(\"Test\", ra=ra, dec=dec, components=[component1])\n",
    "    \n",
    "    spec = source(emod)\n",
    "    spec_binned = powerlaw_binned_spectrum(emod, spec)\n",
    "    \n",
    "    source_counts = np.zeros((len(pointings)*85, len(energy_bins)-1), dtype=np.uint32)\n",
    "    \n",
    "    for p_i, pointing in enumerate(pointings):\n",
    "        if skip_pointing[p_i]:\n",
    "            continue\n",
    "        \n",
    "        resp_mat = resp_mats[p_i]\n",
    "        \n",
    "        count_rates = np.dot(spec_binned, resp_mat)\n",
    "        \n",
    "        for d_i, d in enumerate(dets):\n",
    "            index = p_i * 85 + d\n",
    "            source_counts[index,:] = np.random.poisson(count_rates[d_i,:] * time_elapsed[pointing_index*85 + d])\n",
    "    \n",
    "    return source_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(source_Ks)):\n",
    "    for j in range(len(source_indices)):\n",
    "        \n",
    "        temp_path = f\"{data_path_d}/{i}_{j}\"        \n",
    "        \n",
    "        if not os.path.exists(temp_path):\n",
    "            os.mkdir(temp_path)\n",
    "            \n",
    "        os.popen(f\"cp {data_path}/energy_boundaries.fits {temp_path}/energy_boundaries.fits\")\n",
    "        os.popen(f\"cp {data_path}/pointing.fits {temp_path}/pointing.fits\")\n",
    "\n",
    "                \n",
    "        hdu = fits.BinTableHDU(data=updated_time, name=\"SPI.-OBS.-DTI\") # is all of this correct?\n",
    "        hdu.writeto(f\"{temp_path}/dead_time.fits\")\n",
    "        \n",
    "        source_counts = calc_count_rates(resp_mats, source_ra, source_dec, source_piv, source_Ks[i], source_indices[j])\n",
    "        \n",
    "        total_counts = background_counts.copy()\n",
    "        total_counts[\"COUNTS\"] += source_counts\n",
    "                \n",
    "        hdu = fits.BinTableHDU(data=total_counts, name=\"SPI.-OBS.-DSP\")\n",
    "        hdu.writeto(f\"{temp_path}/evts_det_spec.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"crab_data/0374\"\n",
    "# data_path = \"crab_data/1380\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary\n",
    "\n",
    "source_ra, source_dec = 10, -40\n",
    "source_piv = 100.\n",
    "source_K = 3e-4\n",
    "source_index = -2\n",
    "\n",
    "# secondary\n",
    "s_source_decs = [-43, -50, -60, -85]\n",
    "s_source_Ks = [0.3e-4, 1e-4, 3e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing_index = 1\n",
    "# pointing_index = 4\n",
    "\n",
    "\n",
    "data_path_d = \"simulated_data/0374_const_bkg_sec_source\"\n",
    "# data_path_d = \"simulated_data/1380_const_bkg_sec_source\"\n",
    "\n",
    "\n",
    "if not os.path.exists(f\"{data_path_d}\"):\n",
    "    os.mkdir(f\"{data_path_d}\")\n",
    "    \n",
    "with open(f\"./{data_path_d}/source_params.pickle\", \"wb\") as f:\n",
    "    pickle.dump((source_ra, source_dec, source_piv, source_K, source_index, s_source_decs, s_source_Ks), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Bins\n",
    "with fits.open(f\"{data_path}/energy_boundaries.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    energy_bins = np.append(t[\"E_MIN\"], t[\"E_MAX\"][-1])\n",
    "    \n",
    "# Pointings and Start Times\n",
    "with fits.open(f\"{data_path}/pointing.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    \n",
    "    pointings = np.array(t[\"PTID_SPI\"])\n",
    "    \n",
    "    time_start = np.array(t[\"TSTART\"]) + 2451544.5\n",
    "    time_start = [at.Time(f\"{i}\", format=\"jd\").datetime for i in time_start]\n",
    "    time_start = np.array([datetime.strftime(i,'%y%m%d %H%M%S') for i in time_start])\n",
    "    \n",
    "# Time Elapsed\n",
    "# det=i, pointing_index=j : index = j*85 + i\n",
    "with fits.open(f\"{data_path}/dead_time.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    time_elapsed = np.array(t[\"LIVETIME\"])\n",
    "    \n",
    "updated_time = t.copy()\n",
    "    \n",
    "for i in range(int(len(time_elapsed) / 85)):\n",
    "    if i == pointing_index:\n",
    "        continue\n",
    "    else:\n",
    "        updated_time[i*85 : (i+1)*85] = updated_time[pointing_index*85 : (pointing_index+1)*85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only necessary for 1380\n",
    "skip_pointing = [False] * len(pointings)\n",
    "# skip_pointing[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "\n",
    "with fits.open(f\"{data_path}/evts_det_spec_orig.fits\") as file:\n",
    "    t = Table.read(file[1])\n",
    "    \n",
    "background_counts = t.copy()\n",
    "\n",
    "for i in range(int(len(background_counts) / 85)):\n",
    "    if i == pointing_index:\n",
    "        continue\n",
    "    else:\n",
    "        background_counts[i*85 : (i+1)*85] = background_counts[pointing_index*85 : (pointing_index+1)*85]\n",
    "        \n",
    "background_counts[\"COUNTS\"] = np.random.poisson(background_counts[\"COUNTS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the irfs that are valid between 04/07/17 08:20:06 and 09/02/19 09:59:57 (YY/MM/DD HH:MM:SS)\n"
     ]
    }
   ],
   "source": [
    "assert find_response_version(time_start[0]) == find_response_version(time_start[-1]), \"Versions not constant\"\n",
    "version = find_response_version(time_start[0])\n",
    "rsp_base = ResponseDataRMF.from_version(version)\n",
    "\n",
    "\n",
    "resp_mats = []\n",
    "emod = np.geomspace(10, 3000, 50)\n",
    "\n",
    "for p_i, pointing in enumerate(pointings):\n",
    "    if skip_pointing[p_i]:\n",
    "        continue\n",
    "    \n",
    "    time = time_start[p_i]\n",
    "    dets = get_live_dets(time=time, event_types=[\"single\"])\n",
    "    \n",
    "    rmfs = []\n",
    "    for d in dets:\n",
    "        rmfs.append(ResponseRMFGenerator.from_time(time, d, energy_bins, emod, rsp_base))\n",
    "        \n",
    "    sds = np.empty(0)\n",
    "    for d in range(len(dets)):\n",
    "        sd = SPIDRM(rmfs[d], source_ra, source_dec)\n",
    "        sds = np.append(sds, sd.matrix.T)\n",
    "    resp_mats.append(sds.reshape((len(dets), len(emod)-1, len(energy_bins)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_resp_mats = []\n",
    "\n",
    "for i in range(len(s_source_decs)):\n",
    "    t_resp_mats = []\n",
    "    for p_i, pointing in enumerate(pointings):\n",
    "        if skip_pointing[p_i]:\n",
    "            continue\n",
    "        \n",
    "        time = time_start[p_i]\n",
    "        dets = get_live_dets(time=time, event_types=[\"single\"])\n",
    "        \n",
    "        rmfs = []\n",
    "        for d in dets:\n",
    "            rmfs.append(ResponseRMFGenerator.from_time(time, d, energy_bins, emod, rsp_base))\n",
    "            \n",
    "        sds = np.empty(0)\n",
    "        for d in range(len(dets)):\n",
    "            sd = SPIDRM(rmfs[d], source_ra, s_source_decs[i])\n",
    "            sds = np.append(sds, sd.matrix.T)\n",
    "        t_resp_mats.append(sds.reshape((len(dets), len(emod)-1, len(energy_bins)-1)))\n",
    "    s_resp_mats.append(t_resp_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_count_rates_sec(resp_mats, ra, dec, piv, K, index, s_resp_mats, s_dec, s_K):\n",
    "    pl = Powerlaw()\n",
    "    pl.piv = piv\n",
    "    pl.K = K\n",
    "    pl.index = index\n",
    "    component1 = SpectralComponent(\"pl\", shape=pl)\n",
    "    source = PointSource(\"Test\", ra=ra, dec=dec, components=[component1])\n",
    "    \n",
    "    spec = source(emod)\n",
    "    spec_binned = powerlaw_binned_spectrum(emod, spec)\n",
    "    \n",
    "    s_pl = Powerlaw()\n",
    "    s_pl.piv = piv\n",
    "    s_pl.K = s_K\n",
    "    s_pl.index = index\n",
    "    component1 = SpectralComponent(\"pl\", shape=s_pl)\n",
    "    s_source = PointSource(\"Test\", ra=ra, dec=s_dec, components=[component1])\n",
    "    \n",
    "    s_spec = s_source(emod)\n",
    "    s_spec_binned = powerlaw_binned_spectrum(emod, s_spec)\n",
    "    \n",
    "    source_counts = np.zeros((len(pointings)*85, len(energy_bins)-1))\n",
    "    \n",
    "    s_source_counts = np.zeros((len(pointings)*85, len(energy_bins)-1))\n",
    "        \n",
    "    for p_i, pointing in enumerate(pointings):\n",
    "        if skip_pointing[p_i]:\n",
    "            continue\n",
    "        \n",
    "        resp_mat = resp_mats[p_i]\n",
    "        \n",
    "        count_rates = np.dot(spec_binned, resp_mat)\n",
    "                \n",
    "        for d_i, d in enumerate(dets):\n",
    "            index = p_i * 85 + d\n",
    "            source_counts[index,:] = np.random.poisson(count_rates[d_i,:] * time_elapsed[pointing_index*85 + d])\n",
    "                        \n",
    "        s_resp_mat = s_resp_mats[p_i]\n",
    "        \n",
    "        s_count_rates = np.dot(s_spec_binned, s_resp_mat)\n",
    "                    \n",
    "        for d_i, d in enumerate(dets):\n",
    "            index = p_i * 85 + d\n",
    "            s_source_counts[index,:] = np.random.poisson(s_count_rates[d_i,:] * time_elapsed[pointing_index*85 + d])\n",
    "            \n",
    "    total_source_counts = source_counts + s_source_counts\n",
    "    \n",
    "    # print(source_counts)\n",
    "    # print(s_source_counts)\n",
    "    # print(total_source_counts)\n",
    "    \n",
    "    return total_source_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13. 11. 12. ...  0.  0.  0.]\n",
      " [ 3.  2.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[1. 2. 2. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[14. 13. 14. ...  0.  0.  0.]\n",
      " [ 4.  2.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[14. 12. 15. ...  0.  0.  0.]\n",
      " [ 1.  1.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[2. 4. 7. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[16. 16. 22. ...  0.  0.  0.]\n",
      " [ 1.  2.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[13. 12.  8. ...  0.  0.  0.]\n",
      " [ 2.  2.  6. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[14. 11. 12. ...  0.  0.  0.]\n",
      " [ 2.  1.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[27. 23. 20. ...  0.  0.  0.]\n",
      " [ 4.  3.  8. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[ 8.  7. 15. ...  0.  0.  0.]\n",
      " [ 3.  1.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[1. 3. 1. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 9. 10. 16. ...  0.  0.  0.]\n",
      " [ 4.  2.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[12. 14. 12. ...  0.  0.  0.]\n",
      " [ 4.  1.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[2. 3. 1. ... 0. 0. 0.]\n",
      " [1. 3. 2. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[14. 17. 13. ...  0.  0.  0.]\n",
      " [ 5.  4.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[12. 14.  7. ...  0.  0.  0.]\n",
      " [ 1.  3.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[8. 6. 6. ... 0. 0. 0.]\n",
      " [8. 6. 4. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[20. 20. 13. ...  0.  0.  0.]\n",
      " [ 9.  9.  6. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[11. 15. 12. ...  0.  0.  0.]\n",
      " [ 1.  2.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[11. 15. 12. ...  0.  0.  0.]\n",
      " [ 1.  2.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[15.  9.  7. ...  0.  0.  0.]\n",
      " [ 2.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[15.  9.  7. ...  0.  0.  0.]\n",
      " [ 2.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[19. 12. 22. ...  0.  0.  0.]\n",
      " [ 1.  3.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[19. 12. 22. ...  0.  0.  0.]\n",
      " [ 1.  3.  3. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[14.  6.  7. ...  0.  0.  0.]\n",
      " [ 3.  1.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[14.  6.  7. ...  0.  0.  0.]\n",
      " [ 3.  1.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[10. 19. 15. ...  0.  0.  0.]\n",
      " [ 0.  1.  4. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[10. 19. 15. ...  0.  0.  0.]\n",
      " [ 0.  1.  4. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[17.  8. 11. ...  0.  0.  0.]\n",
      " [ 5.  2.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[17.  8. 11. ...  0.  0.  0.]\n",
      " [ 5.  2.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(s_source_decs)):\n",
    "    for j in range(len(s_source_Ks)):\n",
    "        \n",
    "        temp_path = f\"{data_path_d}/{i}_{j}\"        \n",
    "        \n",
    "        if not os.path.exists(temp_path):\n",
    "            os.mkdir(temp_path)\n",
    "            \n",
    "        os.popen(f\"cp {data_path}/energy_boundaries.fits {temp_path}/energy_boundaries.fits\")\n",
    "        os.popen(f\"cp {data_path}/pointing.fits {temp_path}/pointing.fits\")\n",
    "\n",
    "                \n",
    "        hdu = fits.BinTableHDU(data=updated_time, name=\"SPI.-OBS.-DTI\") # is all of this correct?\n",
    "        hdu.writeto(f\"{temp_path}/dead_time.fits\")\n",
    "        \n",
    "        source_counts = calc_count_rates_sec(resp_mats, source_ra, source_dec, source_piv, source_K, source_index, s_resp_mats[i], s_source_decs[i], s_source_Ks[j])\n",
    "        \n",
    "        total_counts = background_counts.copy()\n",
    "        total_counts[\"COUNTS\"] = source_counts + total_counts[\"COUNTS\"]\n",
    "                \n",
    "        hdu = fits.BinTableHDU(data=total_counts, name=\"SPI.-OBS.-DSP\")\n",
    "        hdu.writeto(f\"{temp_path}/evts_det_spec.fits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IntegralQuery import SearchQuery, IntegralQuery, Filter, Range #################################################\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, SkyOffsetFrame\n",
    "from datetime import datetime\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def calculate_distance_matrix(quick_list, angle_weight, time_weight, max_distance):\n",
    "    l = len(quick_list)\n",
    "    distances = np.full((l,l), 2*max_distance)\n",
    "    \n",
    "    partitions = [0]\n",
    "    for i in range(1,l):\n",
    "        if quick_list[i,2]-quick_list[i-1,2] > max_distance/time_weight:\n",
    "            partitions.append(i)\n",
    "    partitions.append(l)\n",
    "    \n",
    "    for i in range(len(partitions)-1):\n",
    "        for j in range(partitions[i], partitions[i+1]):\n",
    "\n",
    "            for k in range(j+1, partitions[i+1]):\n",
    "                distances[j,k] = distances[k,j] = calculate_distance(quick_list[j],quick_list[k],\n",
    "                                                                     angle_weight,time_weight)\n",
    "                \n",
    "    np.fill_diagonal(distances,0.)\n",
    "            \n",
    "    return np.array(partitions), distances\n",
    "\n",
    "@njit\n",
    "def calculate_distance(point1, point2, angle_weight, time_weight): #include minimum distance ################################################\n",
    "    ang_dis = np.arccos( np.clip(np.array([np.sin(point1[1])*np.sin(point2[1]) \n",
    "                                           + np.cos(point1[1])*np.cos(point2[1]) \n",
    "                                           * np.cos(point1[0] - point2[0])]), -1., 1.) )[0]\n",
    "    time_dis = abs(point1[2] - point2[2])\n",
    "    return ( (angle_weight*ang_dis)**2 + (time_weight*time_dis)**2 )**0.5\n",
    "\n",
    "@njit\n",
    "def find_regions(distances, max_distance, partitions):\n",
    "    regions = []\n",
    "    for i,partition in enumerate(partitions[:-1]):\n",
    "        unconnected = [j for j in range(partition, partitions[i+1])]\n",
    "        while not len(unconnected)==0:\n",
    "            temp_region = [unconnected.pop(0)]\n",
    "            search_index = 0\n",
    "            while search_index < len(temp_region):\n",
    "                l = len(unconnected)\n",
    "                for j in range(l-1,-1,-1):\n",
    "                    if distances[ temp_region[search_index], unconnected[j] ] < max_distance:\n",
    "                        temp_region.append(unconnected.pop(j))\n",
    "                search_index += 1\n",
    "            regions.append(sorted(temp_region))\n",
    "    return regions\n",
    "\n",
    "@njit\n",
    "def choose_random_weighted_interval(weights):\n",
    "    r = np.random.random(1)[0] * np.sum(weights)\n",
    "    s = 0.\n",
    "    for i, w in enumerate(weights):\n",
    "        s += w\n",
    "        if r < s:\n",
    "            return i\n",
    "        \n",
    "@njit\n",
    "def calc_pair_combinations(number):\n",
    "    return (number)*(number-1)/2\n",
    "    \n",
    "    \n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self,\n",
    "                 pointing,\n",
    "                 query):\n",
    "        self.indices = [pointing.index]\n",
    "        self.avg_distance = 0.\n",
    "        self.num_pointings = 1\n",
    "        self.pointings = [pointing]\n",
    "        self.query = query\n",
    "        \n",
    "    def add_pointing(self, pointing):\n",
    "        self.avg_distance = self.calc_new_avg_dist(pointing)\n",
    "        self.indices.append(pointing.index)\n",
    "        self.pointings.append(pointing)\n",
    "        self.num_pointings += 1\n",
    "        \n",
    "    def should_add_pointing(self, pointing):\n",
    "        if self.num_pointings < self.query._cluster_size_range[1]:\n",
    "            if self.find_new_max_dist(pointing) < self.query._max_distance:\n",
    "                if self.num_pointings >= self.query._cluster_size_range[0]:\n",
    "                    if (self.calc_new_avg_dist(pointing)/self.avg_distance ################## make sigmoid? why make sigmoid?\n",
    "                        < self.query._cluster_size_preference_threshold[self.num_pointings\n",
    "                                                                        - self.query._cluster_size_range[0]]):\n",
    "                        return True\n",
    "                else:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "        \n",
    "    def dissolve_cluster(self): ################################\n",
    "        for p in self.pointings:\n",
    "            p.cluster = None\n",
    "            \n",
    "    def finalize_cluster(self): #######################################\n",
    "        for p in self.pointings:\n",
    "            p.cluster = self\n",
    "            \n",
    "        \n",
    "        \n",
    "    def calc_new_avg_dist(self, pointing):\n",
    "        return ((self.avg_distance * calc_pair_combinations(self.num_pointings)\n",
    "                 + np.sum(self.query._distances[pointing.index,self.indices]))\n",
    "                 / calc_pair_combinations(self.num_pointings+1) )\n",
    "        \n",
    "    def find_new_max_dist(self, pointing): # only checks for new pointing!\n",
    "        return np.amax(self.query._distances[pointing.index,self.indices])\n",
    "\n",
    "    def find_closest_pointings(self, cluster2):\n",
    "        d = self.query._distances[self.indices,:][:,cluster2.indices]\n",
    "        c = np.unravel_index(d.argmin(), d.shape)\n",
    "        return self.pointings[c[0]], cluster2.pointings[c[1]]\n",
    "    \n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class Pointing:\n",
    "    '''\n",
    "    Dataclass that represents a single Pointing\n",
    "    '''\n",
    "    scw_id: str\n",
    "    sky_coords: SkyCoord\n",
    "    start_time: datetime\n",
    "    index: int\n",
    "    cluster: Cluster = None\n",
    "    # delete unnecessary clusters and regions ##############################################\n",
    "    \n",
    "    def distance_calculator(self, pointing2, angle_weight: float, time_weight: float): #####################################################\n",
    "        return ( (angle_weight * self.sky_coords.separation(pointing2.sky_coords).deg)**2\n",
    "                + (time_weight * abs( (self.start_time - pointing2.start_time).total_seconds()/86400 ) )**2 )**0.5\n",
    "        \n",
    "    def angle_between_three_pointings(self, pointing2, pointing3, angle_weight, time_weight):\n",
    "        origin = SkyCoord(self.sky_coords.ra.deg, (self.sky_coords.dec.deg%180.)-90., frame=\"icrs\",unit=\"deg\")\n",
    "        origin_Frame = SkyOffsetFrame(origin = origin)\n",
    "        \n",
    "        p1 = self.sky_coords.transform_to(origin_Frame)\n",
    "        p2 = pointing2.sky_coords.transform_to(origin_Frame)\n",
    "        p3 = pointing3.sky_coords.transform_to(origin_Frame)\n",
    "        \n",
    "        a_a = p2.lon.deg - p3.lon.deg\n",
    "        a_d2 = abs(p1.lat.deg - p2.lat.deg) * angle_weight\n",
    "        a_d3 = abs(p1.lat.deg - p3.lat.deg) * angle_weight\n",
    "        \n",
    "        t_d2 = (pointing2.start_time - self.start_time).total_seconds()/86400 * time_weight\n",
    "        t_d3 = (pointing3.start_time - self.start_time).total_seconds()/86400 * time_weight\n",
    "        \n",
    "        return np.arccos( np.clip((a_d2*a_d3*np.cos(np.deg2rad(a_a)) + t_d2*t_d3) \n",
    "                                  / np.linalg.norm([a_d2,t_d2]) / np.linalg.norm([a_d3,t_d3]), -1., 1.) )\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ClusteredQuery:\n",
    "    def __init__(self,\n",
    "                 scw_ids, # Has to be sorted by START_DATE\n",
    "                 angle_weight,\n",
    "                 time_weight,\n",
    "                 max_distance,\n",
    "                 cluster_size_range = (3,5),\n",
    "                 cluster_size_preference_threshold = (5.,5.),\n",
    "                 failed_improvements_max = 4,\n",
    "                 suboptimal_cluster_size_range = (1,2), #has to start at 1\n",
    "                 close_suboptimal_cluster_size_range = (1,3), # above has to be subset\n",
    "                 track_performance = False\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Init the Clustered Query object. Used to cluster pointings\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self._angle_weight = float(angle_weight)\n",
    "        self._time_weight = float(time_weight)\n",
    "        self._max_distance = float(max_distance)\n",
    "        self._cluster_size_range = cluster_size_range\n",
    "        self._cluster_size_preference_threshold = cluster_size_preference_threshold\n",
    "        self._failed_improvements_max = failed_improvements_max\n",
    "        self._suboptimal_cluster_size_range = suboptimal_cluster_size_range\n",
    "        self._close_suboptimal_cluster_size_range = close_suboptimal_cluster_size_range\n",
    "        \n",
    "        self._num_pointings = len(scw_ids)\n",
    "        \n",
    "        self._track_performance = track_performance\n",
    "        if self._track_performance:\n",
    "            self._region_sizes = {}\n",
    "            self._initial_cluster_sizes = self.initialize_size_dictionary()\n",
    "            self._cluster_sizes = self.initialize_size_dictionary()\n",
    "            for i in self._initial_cluster_sizes.keys():\n",
    "                self._initial_cluster_sizes[i] = 0\n",
    "                self._cluster_sizes[i] = 0\n",
    "            self._attempted_improvements = 0\n",
    "            self._implemented_improvements = 0\n",
    "            self._dead_ends = 0\n",
    "            \n",
    "            \n",
    "        \n",
    "        quick_list = np.zeros((self._num_pointings, 3))\n",
    "        quick_list[:,0:2] = scw_ids[:,1:3]\n",
    "        for i in range(self._num_pointings):\n",
    "            quick_list[i,2] = (scw_ids[i,3] - datetime(2000,1,1,0,0,0)).total_seconds()/86400\n",
    "            \n",
    "        partitions, self._distances = calculate_distance_matrix(quick_list, angle_weight, time_weight, self._max_distance)\n",
    "                \n",
    "        self._region_indices = find_regions(self._distances, self._max_distance, partitions)\n",
    "        \n",
    "        self._pointings = np.array([Pointing(pointing[0],\n",
    "                                            SkyCoord(pointing[1],pointing[2],frame=\"icrs\",unit=\"deg\"),\n",
    "                                            pointing[3], index)\n",
    "                                    for index, pointing in enumerate(scw_ids)])\n",
    "        \n",
    "        self.clusters = self.initialize_size_dictionary()\n",
    "        \n",
    "        \n",
    "        for i in self._region_indices:\n",
    "            Region(i, self)\n",
    "            \n",
    "        if self._track_performance:\n",
    "            for i in self._region_indices:\n",
    "                if len(i) in self._region_sizes:\n",
    "                    self._region_sizes[len(i)] += 1\n",
    "                else:\n",
    "                    self._region_sizes[len(i)] = 1\n",
    "            for clusters in self.clusters.values():\n",
    "                for cluster in clusters:\n",
    "                    self._cluster_sizes[cluster.num_pointings] += 1\n",
    "            \n",
    "        print()\n",
    "        print(\"All Done\")\n",
    "        clustered = set()\n",
    "        n = 0\n",
    "        \n",
    "        for key, value in self.clusters.items():\n",
    "            for c in value:\n",
    "                print(f\"{c.indices}, {c.avg_distance}\")\n",
    "                clustered = clustered | set(c.indices)\n",
    "                n += c.num_pointings\n",
    "                \n",
    "        missing = [i for i in range(self._num_pointings) if i not in clustered]\n",
    "        print()\n",
    "        print(missing)\n",
    "        print(self._num_pointings, n)\n",
    "        \n",
    "        if self._track_performance:\n",
    "            print()\n",
    "            print()\n",
    "            print(\"Performance Review!\")\n",
    "            print()\n",
    "            print(\"Region Sizes:\")\n",
    "            print(self._region_sizes)\n",
    "            print()\n",
    "            print(\"Initial Cluster Sizes:\")\n",
    "            print(self._initial_cluster_sizes)\n",
    "            print()\n",
    "            print(\"Final Cluster Sizes:\")\n",
    "            print(self._cluster_sizes)\n",
    "            print()\n",
    "            print(\"Attempted Improvements:\")\n",
    "            print(self._attempted_improvements)\n",
    "            print()\n",
    "            print(\"Implemented Improvements:\")\n",
    "            print(self._implemented_improvements)\n",
    "            print()\n",
    "            print(\"Dead-End Clustering Paths:\")\n",
    "            print(self._dead_ends)\n",
    "            \n",
    "                \n",
    "        \n",
    "    def initialize_size_dictionary(self):\n",
    "        dict = {}\n",
    "        for i in range(self._cluster_size_range[1]):\n",
    "            dict[i+1]=[]\n",
    "        return dict\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class Region:\n",
    "    def __init__(self,\n",
    "                 region_indices,\n",
    "                 query\n",
    "                 ):\n",
    "        self.indices = region_indices\n",
    "        \n",
    "        self.query = query\n",
    "        \n",
    "        self.clusters = self.query.initialize_size_dictionary()\n",
    "        self.potential_clusters1 = self.query.initialize_size_dictionary()\n",
    "        self.potential_clusters2 = self.query.initialize_size_dictionary()\n",
    "            \n",
    "\n",
    "        \n",
    "        self.initial_clustering()\n",
    "        \n",
    "        if self.query._track_performance:\n",
    "            for clusters in self.clusters.values():\n",
    "                for cluster in clusters:\n",
    "                    self.query._initial_cluster_sizes[cluster.num_pointings] += 1\n",
    "        \n",
    "        for key, value in self.clusters.items():\n",
    "            for c in value:\n",
    "                print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        \n",
    "        \n",
    "        failed_improvements = 0\n",
    "        while failed_improvements < self.query._failed_improvements_max and self.has_suboptimal_clusters():\n",
    "            if self.query._track_performance:\n",
    "                self.query._attempted_improvements += 1\n",
    "            if not self.attempt_improvement():\n",
    "                failed_improvements += 1\n",
    "            else:\n",
    "                failed_improvements = 0\n",
    "                if self.query._track_performance:\n",
    "                    self.query._implemented_improvements += 1\n",
    "                \n",
    "        for size, clusters in self.clusters.items():\n",
    "            self.query.clusters[size].extend(clusters)\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print(\"Finishing Region!\")\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "                \n",
    "        \n",
    "        \n",
    "    \n",
    "    def initial_clustering(self): ################## also check following pointings\n",
    "        cluster = Cluster(self.query._pointings[self.indices[0]], self.query)\n",
    "        for index in self.indices[1:]:\n",
    "            if cluster.should_add_pointing(self.query._pointings[index]):\n",
    "                cluster.add_pointing(self.query._pointings[index])\n",
    "            else:\n",
    "                cluster.finalize_cluster()\n",
    "                self.clusters[cluster.num_pointings].append(cluster)\n",
    "                cluster = Cluster(self.query._pointings[index], self.query)\n",
    "        cluster.finalize_cluster()\n",
    "        self.clusters[cluster.num_pointings].append(cluster)\n",
    "        \n",
    "    def attempt_improvement(self):\n",
    "        print()\n",
    "        print(\"Attempting Improvement!\")\n",
    "        print()\n",
    "        c1 = self.find_suboptimal_cluster()\n",
    "        c2 = self.find_close_suboptimal_cluster(c1)\n",
    "        found_path, recluster_indices = self.find_cluster_path(c1,c2)\n",
    "        if not found_path:\n",
    "            return False\n",
    "        else:\n",
    "            self.recluster_pointings(recluster_indices, c1)\n",
    "        print()\n",
    "        print(\"Done!\")\n",
    "        print()\n",
    "        for key, value in self.clusters.items():\n",
    "            for c in value:\n",
    "                print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        print()\n",
    "        for key, value in self.potential_clusters1.items():\n",
    "            for c in value:\n",
    "                print(f\"{c.indices}, {c.avg_distance}\")\n",
    "        print()\n",
    "        for key, value in self.potential_clusters2.items():\n",
    "            for c in value:\n",
    "                print(f\"{c.indices}, {c.avg_distance}\")\n",
    "                \n",
    "        print(f\"Comparison: {self.calc_clustering_cost(self.potential_clusters1)}, {self.calc_clustering_cost(self.potential_clusters2)}\")\n",
    "        if self.calc_clustering_cost(self.potential_clusters1) > self.calc_clustering_cost(self.potential_clusters2):\n",
    "            self.implement(self.potential_clusters2, True)\n",
    "            print()\n",
    "            print(\"Implemented!\")\n",
    "            for key, value in self.clusters.items():\n",
    "                for c in value:\n",
    "                    print(f\"{c.indices}, {c.avg_distance}\")\n",
    "            print()\n",
    "            return True\n",
    "        else:\n",
    "            self.implement(self.potential_clusters1, False)\n",
    "            print()\n",
    "            print(\"Rejected!\")\n",
    "            for key, value in self.clusters.items():\n",
    "                for c in value:\n",
    "                    print(f\"{c.indices}, {c.avg_distance}\")\n",
    "            print()\n",
    "            return False\n",
    "            \n",
    "        \n",
    "    \n",
    "    def find_suboptimal_cluster(self):\n",
    "        size_weights = np.array([len(self.clusters[i]) / i**2\n",
    "                                 for i in range(self.query._suboptimal_cluster_size_range[0],\n",
    "                                                self.query._suboptimal_cluster_size_range[1] + 1)])\n",
    "        size = choose_random_weighted_interval(size_weights) + 1\n",
    "        index = np.random.randint(len(self.clusters[size]))\n",
    "        cluster = self.clusters[size].pop(index)\n",
    "        self.potential_clusters1[size].append(cluster)\n",
    "        return cluster\n",
    "    \n",
    "    def find_close_suboptimal_cluster(self, cluster): ################################# maximum distance?\n",
    "        clusters = []\n",
    "        cluster_size_indices = [0]\n",
    "        for i in range(self.query._close_suboptimal_cluster_size_range[0], \n",
    "                       self.query._close_suboptimal_cluster_size_range[1] + 1):\n",
    "            clusters.extend(self.clusters[i])\n",
    "            cluster_size_indices.append( len(self.clusters[i]) + cluster_size_indices[i-1] )\n",
    "        cluster_weights = np.zeros(len(clusters))\n",
    "        for i, c in enumerate(clusters):\n",
    "            d = self.query._distances[cluster.indices,:][:,c.indices]\n",
    "            cluster_weights[i] = np.exp( -5.*np.amin(d) / self.query._max_distance ) ##### weights\n",
    "        for i in range(1, self.query._close_suboptimal_cluster_size_range[1] + 1):\n",
    "            cluster_weights[cluster_size_indices[i-1]:cluster_size_indices[i]] /= i\n",
    "        index = choose_random_weighted_interval( cluster_weights )\n",
    "        for size, csi in enumerate(cluster_size_indices):\n",
    "            if not index >= csi:\n",
    "                break\n",
    "        true_index = index - cluster_size_indices[size-1]\n",
    "        \n",
    "        cluster2 = self.clusters[size].pop(true_index)\n",
    "        self.potential_clusters1[size].append(cluster2)\n",
    "        return cluster2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def find_cluster_path(self, cluster1, cluster2):\n",
    "        indices_in = set(cluster1.indices)\n",
    "        indices_to = set(cluster2.indices)\n",
    "        arrived = False\n",
    "        while not arrived:\n",
    "        \n",
    "            indices_out = np.array([i for i in self.indices if i not in indices_in])\n",
    "            pointing1, pointing2 = cluster1.find_closest_pointings(cluster2)\n",
    "            print(pointing1.index, pointing2.index)\n",
    "\n",
    "            close_indices = self.find_closest_points(pointing1.index, indices_out, 4) #### use 3?\n",
    "            print(close_indices)\n",
    "            \n",
    "            angle = np.vectorize(lambda p: pointing1.angle_between_three_pointings(pointing2, p, self.query._angle_weight,\n",
    "                                                                                   self.query._time_weight))\n",
    "            \n",
    "            angles_filtered = angle(self.query._pointings[close_indices])\n",
    "            \n",
    "            distances_filtered = self.query._distances[pointing1.index, close_indices]\n",
    "            \n",
    "            close_indices_weights = ((distances_filtered < self.query._max_distance) \n",
    "                                     * np.exp(-5. * distances_filtered / self.query._max_distance) ##### weights\n",
    "                                     * np.cos(angles_filtered/2.)**8)\n",
    "            \n",
    "            print(angles_filtered)\n",
    "            print(distances_filtered)\n",
    "            print(close_indices_weights)\n",
    "            \n",
    "            random_index = choose_random_weighted_interval(close_indices_weights)\n",
    "            \n",
    "            if (random_index is None) or (np.amax(np.cos(angles_filtered)) < 0.):\n",
    "                print(\"Cannot go forwards, or reached dead end!\")\n",
    "                self.implement(self.potential_clusters1, False)\n",
    "                if self.query._track_performance:\n",
    "                    self.query._dead_ends += 1\n",
    "                return False, None\n",
    "\n",
    "            index = close_indices[random_index]\n",
    "            \n",
    "            cluster1 = self.query._pointings[index].cluster\n",
    "            indices_in = indices_in | set(cluster1.indices)\n",
    "            if index in indices_to:\n",
    "                arrived = True\n",
    "            else:\n",
    "                self.clusters[cluster1.num_pointings].remove(cluster1)\n",
    "                self.potential_clusters1[cluster1.num_pointings].append(cluster1)\n",
    "        \n",
    "        return True, indices_in\n",
    "        \n",
    "        \n",
    "    def recluster_pointings(self, recluster_indices, start_cluster):\n",
    "        \n",
    "        index = start_cluster.indices[choose_random_weighted_interval( \n",
    "                                      np.exp(np.average(self.query._distances[start_cluster.indices,:][:,list(recluster_indices)], axis=1) ##### weights\n",
    "                                             * 5. / self.query._max_distance) )]\n",
    "        \n",
    "        cluster = Cluster(self.query._pointings[index], self.query)\n",
    "        already_clustered = {index}\n",
    "        not_clustered = np.array([i for i in recluster_indices if i not in already_clustered])\n",
    "        \n",
    "        print()\n",
    "        print(\"Recluster Pointings!\")\n",
    "        \n",
    "        added_all_clusters = False\n",
    "        while not_clustered.size != 0: # check case of only one left\n",
    "            print()\n",
    "            print(\"New Cluster!\")\n",
    "\n",
    "            cluster_done = False\n",
    "            \n",
    "            while not cluster_done:\n",
    "                print()\n",
    "                print(\"Continue Cluster!\")\n",
    "                print(index, cluster.indices)\n",
    "                print(already_clustered)\n",
    "                print(not_clustered)\n",
    "                \n",
    "                close_indices = self.find_closest_points(index, not_clustered, 3) ############# use 2?\n",
    "                \n",
    "                internal_distances = np.average(self.query._distances[cluster.indices,:][:,close_indices], axis=0)\n",
    "                external_distances = np.average(self.query._distances[close_indices,:][:,close_indices], axis=0)\n",
    "                \n",
    "                close_indices_weights = np.exp( (5.*external_distances - 5.*internal_distances) / self.query._max_distance ) ##### weights\n",
    "                \n",
    "                print(close_indices)\n",
    "                print(internal_distances)\n",
    "                print(external_distances)\n",
    "                print(close_indices_weights)\n",
    "                \n",
    "                added = False\n",
    "                while not added:\n",
    "                    random_index = choose_random_weighted_interval(close_indices_weights)\n",
    "                    print(random_index)\n",
    "                    if random_index is None:\n",
    "                        cluster_done = True\n",
    "                        print(\"Found None!\")\n",
    "                        break\n",
    "                    \n",
    "                    index = close_indices[random_index]\n",
    "                    print(index)\n",
    "                    if cluster.should_add_pointing(self.query._pointings[index]):\n",
    "                        added = True\n",
    "                        cluster.add_pointing(self.query._pointings[index])\n",
    "                        already_clustered.add(index)\n",
    "                        not_clustered = np.array([i for i in recluster_indices if i not in already_clustered])\n",
    "                        \n",
    "                        print(\"Added!\")\n",
    "                        \n",
    "                        if cluster.num_pointings == self.query._cluster_size_range[1]:\n",
    "                            cluster_done = True\n",
    "                        \n",
    "                            \n",
    "                            \n",
    "                    else:\n",
    "                        close_indices_weights[random_index] = 0.\n",
    "                \n",
    "                if not_clustered.size == 0:\n",
    "                    self.potential_clusters2[cluster.num_pointings].append(cluster)\n",
    "                    added_all_clusters = True\n",
    "                    break\n",
    "                \n",
    "                if cluster_done:\n",
    "                    self.potential_clusters2[cluster.num_pointings].append(cluster)\n",
    "                    \n",
    "                    weights = np.exp(4.*external_distances / self.query._max_distance)\n",
    "                    if added:\n",
    "                        weights[random_index] = 0.\n",
    "                    index = close_indices[choose_random_weighted_interval(weights)]\n",
    "                    cluster = Cluster(self.query._pointings[index], self.query)\n",
    "                    already_clustered.add(index)\n",
    "                    not_clustered = np.array([i for i in recluster_indices if i not in already_clustered])\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    index = cluster.indices[np.random.randint(cluster.num_pointings)]\n",
    "                    \n",
    "        if not added_all_clusters:\n",
    "            self.potential_clusters2[cluster.num_pointings].append(cluster)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    def find_closest_points(self, start_index, search_indices, number_multiplier):\n",
    "        num_points = min(len(search_indices), self.query._cluster_size_range[1]*number_multiplier)\n",
    "        sortable_pointings = [i for i in range(num_points)]\n",
    "        distances = self.query._distances[start_index,search_indices]\n",
    "        return search_indices[np.argpartition(distances, sortable_pointings)[:num_points]]\n",
    "\n",
    "\n",
    "            \n",
    "    def calc_clustering_cost(self, cluster_dict):\n",
    "        n = 0\n",
    "        avg_d = 0.\n",
    "        for clusters in cluster_dict.values():\n",
    "            for cluster in clusters:\n",
    "                n += 1\n",
    "                if cluster.num_pointings == 1:\n",
    "                    avg_d += self.query._max_distance\n",
    "                else:\n",
    "                    avg_d += cluster.avg_distance\n",
    "\n",
    "        return n + avg_d/n / self.query._max_distance\n",
    "        \n",
    "        \n",
    "    \n",
    "    def has_suboptimal_clusters(self):\n",
    "        s = 0\n",
    "        for i in range(self.query._suboptimal_cluster_size_range[0], \n",
    "                       self.query._suboptimal_cluster_size_range[1] + 1):\n",
    "            s += len(self.clusters[i])\n",
    "        if s >= 2:\n",
    "            return True\n",
    "        elif s >= 1:\n",
    "            for i in range(self.query._suboptimal_cluster_size_range[1] + 1,\n",
    "                           self.query._close_suboptimal_cluster_size_range[1] + 1):\n",
    "                s += len(self.clusters[i])\n",
    "            if s >= 2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def implement(self, potential_clusters, finalize):\n",
    "        for size, clusters in potential_clusters.items():\n",
    "            if finalize:\n",
    "                for cluster in clusters:\n",
    "                    cluster.finalize_cluster()\n",
    "            self.clusters[size].extend(clusters)\n",
    "        self.potential_clusters1 = self.query.initialize_size_dictionary()\n",
    "        self.potential_clusters2 = self.query.initialize_size_dictionary()\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchquerry = SearchQuery(object_name=\"Cyg X-1\", resultmax=0)\n",
    "cat = IntegralQuery(searchquerry)\n",
    "f = Filter(SCW_TYPE=\"POINTING\", SCW_VER=1)\n",
    "scw_ids = cat.apply_filter(f,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ClusteredQuery(scw_ids[:4], 1, 1, 2.8, track_performance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ClusteredQuery(scw_ids, 1, 1, 2.8, track_performance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "\n",
    "def actualsize(input_obj):\n",
    "    memory_size = 0\n",
    "    ids = set()\n",
    "    objects = [input_obj]\n",
    "    while objects:\n",
    "        new = []\n",
    "        for obj in objects:\n",
    "            if id(obj) not in ids:\n",
    "                ids.add(id(obj))\n",
    "                memory_size += sys.getsizeof(obj)\n",
    "                new.append(obj)\n",
    "        objects = gc.get_referents(*new)\n",
    "    return memory_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualsize(test), test._distances.nbytes, scw_ids.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sys import getsizeof, stderr\n",
    "from itertools import chain\n",
    "from collections import deque\n",
    "try:\n",
    "    from reprlib import repr\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "def total_size(o, handlers={}, verbose=False):\n",
    "    \"\"\" Returns the approximate memory footprint an object and all of its contents.\n",
    "\n",
    "    Automatically finds the contents of the following builtin containers and\n",
    "    their subclasses:  tuple, list, deque, dict, set and frozenset.\n",
    "    To search other containers, add handlers to iterate over their contents:\n",
    "\n",
    "        handlers = {SomeContainerClass: iter,\n",
    "                    OtherContainerClass: OtherContainerClass.get_elements}\n",
    "\n",
    "    \"\"\"\n",
    "    dict_handler = lambda d: chain.from_iterable(d.items())\n",
    "    all_handlers = {tuple: iter,\n",
    "                    list: iter,\n",
    "                    deque: iter,\n",
    "                    dict: dict_handler,\n",
    "                    set: iter,\n",
    "                    frozenset: iter,\n",
    "                   }\n",
    "    all_handlers.update(handlers)     # user handlers take precedence\n",
    "    seen = set()                      # track which object id's have already been seen\n",
    "    default_size = getsizeof(0)       # estimate sizeof object without __sizeof__\n",
    "\n",
    "    def sizeof(o):\n",
    "        if id(o) in seen:       # do not double count the same object\n",
    "            return 0\n",
    "        seen.add(id(o))\n",
    "        s = getsizeof(o, default_size)\n",
    "\n",
    "        if verbose:\n",
    "            print(s, type(o), repr(o), file=stderr)\n",
    "\n",
    "        for typ, handler in all_handlers.items():\n",
    "            if isinstance(o, typ):\n",
    "                s += sum(map(sizeof, handler(o)))\n",
    "                break\n",
    "        else:\n",
    "            if not hasattr(o.__class__, '__slots__'):\n",
    "                if hasattr(o, '__dict__'):\n",
    "                    s+=sizeof(o.__dict__) # no __slots__ *usually* means a __dict__, but some special builtin classes (such as `type(None)`) have neither\n",
    "                # else, `o` has no attributes at all, so sys.getsizeof() actually returned the correct value\n",
    "            else:\n",
    "                s+=sum(sizeof(getattr(o, x)) for x in o.__class__.__slots__ if hasattr(o, x))\n",
    "        return s\n",
    "\n",
    "    return sizeof(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size(test._distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing1 = test._pointings[1010]\n",
    "pointing2 = test._pointings[1008]\n",
    "p = test._pointings[1009]\n",
    "pointing1.angle_between_three_pointings(pointing2, p, 1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing1, pointing2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing1.scw_id == p.scw_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('MT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77c6aaad9a34bae581a83e51509dc60b9a05d4f3ba3ef918f772e036566f2e96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
